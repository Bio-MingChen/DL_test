{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "\n",
    "class SimpleSTRAFE(nn.Module):\n",
    "    def __init__(self, vocab_size=1000, embedding_dim=64, max_visits=20, max_time=12):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_visits = max_visits\n",
    "        self.max_time = max_time\n",
    "\n",
    "        # 每个诊断 code 的嵌入\n",
    "        self.concept_embedder = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # 每次 visit 的时间位置嵌入（可选的 index-based 时间编码）\n",
    "        self.time_embedder = nn.Embedding(max_visits, embedding_dim)\n",
    "\n",
    "        # visit 序列 → Transformer 表示\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=4, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        # Conv 将 visit 序列对齐到时间轴（如：48个月）\n",
    "        self.conv = nn.Conv1d(in_channels=max_visits, out_channels=max_time, kernel_size=1)\n",
    "\n",
    "        # MLP → 每月的生存风险概率\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, visit_codes, visit_times):\n",
    "        \"\"\"\n",
    "        visit_codes: [B, V, C] -> 每次 visit 的多个诊断 code id\n",
    "        visit_times: [B, V]    -> 每次 visit 的时间（整数）\n",
    "        \"\"\"\n",
    "        B, V, C = visit_codes.shape\n",
    "\n",
    "        # 将每个 code 嵌入后，对每次 visit 内 code 求和\n",
    "        code_embed = self.concept_embedder(visit_codes)  # [B, V, C, D]\n",
    "        visit_embed = code_embed.sum(dim=2)              # [B, V, D]\n",
    "\n",
    "        # 加上 visit 时间嵌入\n",
    "        time_embed = self.time_embedder(visit_times)     # [B, V, D]\n",
    "        x = visit_embed + time_embed                     # [B, V, D]\n",
    "\n",
    "        # visit 序列经过 self-attention 建模\n",
    "        x = self.transformer(x)                          # [B, V, D]\n",
    "\n",
    "        # Conv 将 V 维映射到 T 维（月）\n",
    "        x = self.conv(x)                                 # [B, T, D]\n",
    "\n",
    "        # 对每月的表示进行 MLP → 得到每月生存概率\n",
    "        x = self.mlp(x).squeeze(-1)                      # [B, T]\n",
    "        return x\n",
    "\n",
    "\n",
    "def strafe_loss(pred_q, event_time, event_indicator):\n",
    "    B, T = pred_q.shape\n",
    "    eps = 1e-7\n",
    "    S_hat = torch.cumprod(pred_q, dim=1)  # [B, T]\n",
    "\n",
    "    loss = 0.0\n",
    "    for i in range(B):\n",
    "        T_i = event_time[i]\n",
    "        S_i = S_hat[i]\n",
    "        if event_indicator[i] == 1:\n",
    "            pre_event = torch.log(S_i[:T_i] + eps).sum()\n",
    "            post_event = torch.log(1 - S_i[T_i:] + eps).sum()\n",
    "            loss -= pre_event + post_event\n",
    "        else:\n",
    "            censored = torch.log(S_i[:T_i] + eps).sum()\n",
    "            loss -= censored\n",
    "    return loss / B\n",
    "\n",
    "def generate_toy_data(B=32, V=20, C=5, T=12, vocab_size=1000):\n",
    "    visit_codes = torch.randint(0, vocab_size, (B, V, C))\n",
    "    visit_times = torch.arange(V).unsqueeze(0).repeat(B, 1)\n",
    "    event_time = torch.randint(4, T, (B,))\n",
    "    event_indicator = torch.randint(0, 2, (B,))\n",
    "    return visit_codes, visit_times, event_time, event_indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "B, V, C, T = 4, 20, 5, 12  # 4个病人, 每人20次visit, 每次5个code, 输出12个月预测\n",
    "dummy_codes = torch.randint(0, 1000, (B, V, C))\n",
    "dummy_times = torch.arange(V).unsqueeze(0).repeat(B, 1)\n",
    "\n",
    "model = SimpleSTRAFE()\n",
    "output = model(dummy_codes, dummy_times)\n",
    "\n",
    "print(output.shape)  # 应该是 [4, 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4505, 0.4602, 0.4558, 0.4589, 0.4776, 0.4017, 0.4875, 0.5181, 0.4545,\n",
       "         0.4272, 0.4611, 0.4728],\n",
       "        [0.4362, 0.4495, 0.4750, 0.4641, 0.4978, 0.4602, 0.4743, 0.4571, 0.4080,\n",
       "         0.4644, 0.4563, 0.4638],\n",
       "        [0.4627, 0.4417, 0.4815, 0.4510, 0.4749, 0.4213, 0.4380, 0.5073, 0.4812,\n",
       "         0.5123, 0.4559, 0.4555],\n",
       "        [0.4153, 0.4191, 0.4433, 0.4569, 0.4865, 0.4641, 0.4861, 0.4699, 0.4525,\n",
       "         0.4798, 0.4738, 0.4324]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 7/10 [00:00<00:00, 32.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 25.1079\n",
      "Epoch 2, Loss: 17.0588\n",
      "Epoch 3, Loss: 16.3907\n",
      "Epoch 4, Loss: 15.0230\n",
      "Epoch 5, Loss: 12.8963\n",
      "Epoch 6, Loss: 10.8966\n",
      "Epoch 7, Loss: 10.5710\n",
      "Epoch 8, Loss: 9.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 9.1118\n",
      "Epoch 10, Loss: 7.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleSTRAFE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in trange(10, desc=\"Training\"):\n",
    "    model.train()\n",
    "    visit_codes, visit_times, event_time, event_indicator = generate_toy_data()\n",
    "    pred_q = model(visit_codes, visit_times)\n",
    "    loss = strafe_loss(pred_q, event_time, event_indicator)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted survival probabilities:\n",
      " tensor([[0.8595, 0.6830, 0.6702, 0.5311, 0.3914, 0.2687, 0.1859, 0.1058, 0.0726,\n",
      "         0.0467, 0.0347, 0.0206],\n",
      "        [0.8587, 0.6879, 0.6751, 0.5367, 0.3915, 0.2686, 0.1863, 0.1052, 0.0717,\n",
      "         0.0476, 0.0353, 0.0211],\n",
      "        [0.8549, 0.6867, 0.6738, 0.5355, 0.3922, 0.2689, 0.1875, 0.1062, 0.0728,\n",
      "         0.0484, 0.0358, 0.0213],\n",
      "        [0.8652, 0.6903, 0.6776, 0.5379, 0.3903, 0.2663, 0.1855, 0.1046, 0.0714,\n",
      "         0.0467, 0.0343, 0.0202]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    visit_codes, visit_times, event_time, event_indicator = generate_toy_data(B=4)\n",
    "    pred_q = model(visit_codes, visit_times)\n",
    "    S_hat = torch.cumprod(pred_q, dim=1)\n",
    "    print(\"Predicted survival probabilities:\\n\", S_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
