{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "def make_dataset(tissue, sample, num_extra=0):\n",
    "    our_data = processed_adata[processed_adata.obs['patient']==sample]\n",
    "    our_data = our_data[our_data.obs['tissue']==tissue]\n",
    "    res_numpy = our_data.X\n",
    "    extra_index = np.random.choice(res_numpy.shape[0], num_extra, replace=True)\n",
    "    extra_res_numpy = res_numpy[extra_index]\n",
    "    res_numpy = np.concatenate([res_numpy, extra_res_numpy], axis=0)\n",
    "    final_res = torch.from_numpy(res_numpy)\n",
    "    return final_res\n",
    "\n",
    "\n",
    "patient_to_label = {\n",
    "    f'BC{i + 1}': i for i in range(8)\n",
    "}\n",
    "\n",
    "\n",
    "def make_data_loader(tissue, samples, with_labels=True, batch_size=1<<7):\n",
    "    our_data = processed_adata[processed_adata.obs['tissue']==tissue]\n",
    "    sample_to_more_data = {\n",
    "        sample: our_data[our_data.obs['patient']==sample]\n",
    "        for sample in samples\n",
    "    }\n",
    "    \n",
    "    res = sample_to_more_data[samples[0]]\n",
    "    res_labels = np.zeros(res.shape[0]) + patient_to_label[samples[0]]\n",
    "    res = res.concatenate(*[v for k, v in sample_to_more_data.items() if k != samples[0]])\n",
    "    res_labels = np.concatenate([res_labels] + [ np.zeros(v.shape[0]) + patient_to_label[k] for k, v in sample_to_more_data.items() if k != samples[0]])\n",
    "    res_numpy = res.X\n",
    "    \n",
    "    from_which = [\n",
    "        torch.from_numpy(res_numpy),\n",
    "    ]\n",
    "    \n",
    "    if with_labels:\n",
    "        from_which.append(torch.from_numpy(res_labels))\n",
    "        \n",
    "    final_res = DataLoader(\n",
    "        TensorDataset(\n",
    "            *from_which,\n",
    "        ), batch_size=batch_size, shuffle=True,\n",
    "        num_workers=1, pin_memory=True, drop_last=True,\n",
    "    )\n",
    "    return final_res\n",
    "\n",
    "def make_train_test_split_tensors(tissue, train_samples, test_samples):\n",
    "    our_data = processed_adata[processed_adata.obs['tissue']==tissue]\n",
    "    sample_to_more_data = {\n",
    "        sample: our_data[our_data.obs['patient']==sample]\n",
    "        for sample in train_samples + test_samples\n",
    "    }\n",
    "    \n",
    "    res_train = sample_to_more_data[train_samples[0]]\n",
    "    if len(train_samples) > 1:\n",
    "        res_train = res_train.concatenate(*[v for k, v in sample_to_more_data.items() if k != train_samples[0] and k in train_samples])\n",
    "    res_test = sample_to_more_data[test_samples[0]]\n",
    "    if len(test_samples) > 1:\n",
    "        res_test = res_test.concatenate(*[v for k, v in sample_to_more_data.items() if k != test_samples[0] and k in test_samples])\n",
    "    return torch.from_numpy(res_train.X).to('cpu'), torch.from_numpy(res_test.X).to('cpu')\n",
    "    \n",
    "###### BELOW are more models and more losses\n",
    "\n",
    "# we now have information regarding the spatiality of the VIM gene\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# no tesnorflow, being very uncooperative\n",
    "import torch\n",
    "# import torchvision\n",
    "# import torchsummary\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as U\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.extend([\".\", \"..\"])\n",
    "\n",
    "def turn_on_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "def turn_off_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "        \n",
    "# better new arch    \n",
    "class StandardEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=512):\n",
    "        super(StandardEncoder, self).__init__()\n",
    "        self.part1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # x tra here\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),  # x tra end \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(512, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.to_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.to_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.part1(x)\n",
    "        return self.to_mean(x), self.to_logvar(x)\n",
    "    \n",
    "    \n",
    "class StandardDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=512, no_final_relu=False):\n",
    "        super(StandardDecoder, self).__init__()\n",
    "     \n",
    "        \n",
    "        # this is for the case of non-zinb\n",
    "        if no_final_relu:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),  # x tra start here\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),  # xtra end\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, input_dim),\n",
    "#                 nn.ReLU(),  # do the activation here\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),  # x tra start here\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),  # xtra end\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, input_dim),\n",
    "                nn.ReLU(),  # do the activation here\n",
    "            )\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    # returns a tuple regardless\n",
    "    def forward(self, x):\n",
    "        res = self.net(x)\n",
    "        return res\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, spectral=True, end_dim=2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        if spectral:\n",
    "            self.net = nn.Sequential(\n",
    "                U.spectral_norm(nn.Linear(latent_dim, 1<<6)),\n",
    "                nn.ReLU(),\n",
    "                U.spectral_norm(nn.Linear(1<<6, 1<<5)),\n",
    "                nn.ReLU(),\n",
    "                U.spectral_norm(nn.Linear(1<<5, 1<<5)),\n",
    "                nn.ReLU(),\n",
    "                U.spectral_norm(nn.Linear(1<<5, end_dim)),\n",
    "    #             nn.Sigmoid(), just do w logits for now \n",
    "            )\n",
    "        else:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 1<<6),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1<<6, 1<<5),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1<<5, 1<<5),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1<<5, end_dim),\n",
    "    #             nn.Sigmoid(), just do w logits for now \n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, is_vae=True, use_latent_norm=True):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.is_vae = is_vae\n",
    "        self.latent_normalizer = (\n",
    "            nn.BatchNorm1d(self.encoder.latent_dim) if 1\n",
    "            else nn.Sigmoid()\n",
    "        )\n",
    "        self.use_latent_norm = use_latent_norm \n",
    "        \n",
    "    def reparam_trick(self, mean, logvar):\n",
    "        sigma = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(sigma)\n",
    "        res = (\n",
    "            mean + eps*sigma if self.is_vae\n",
    "            else mean\n",
    "        )\n",
    "        return res\n",
    "        # below is stupid garbo\n",
    "        # this was a massive BUG\n",
    "#         return mean + eps*sigma\n",
    "#         return mean  # for non variational version, uncomment\n",
    "    \n",
    "    def get_latent(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "            \n",
    "        if self.use_latent_norm:\n",
    "            mean = self.latent_normalizer(mean)\n",
    "            logvar = self.latent_normalizer(logvar)\n",
    "            \n",
    "        return self.reparam_trick(mean, logvar)\n",
    "    \n",
    "    def forward(self, x, noise_latent_lambda=0.):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        \n",
    "        if self.use_latent_norm:\n",
    "            if 0:\n",
    "                mean = self.latent_normalizer(mean)\n",
    "                logvar = self.latent_normalizer(logvar)\n",
    "            \n",
    "            \n",
    "                latent = self.reparam_trick(mean, logvar)\n",
    "            else:\n",
    "                latent = self.reparam_trick(mean, logvar)\n",
    "                latent = self.latent_normalizer(latent)\n",
    "        else:\n",
    "            latent = self.reparam_trick(mean, logvar)\n",
    "            \n",
    "        if noise_latent_lambda:\n",
    "            latent = latent + noise_latent_lambda*torch.randn_like(latent)\n",
    "            \n",
    "        \n",
    "#         m_bar, pi, theta = self.decoder(latent)\n",
    "        # return everything , last 3 are mean, logvar, latent\n",
    "\n",
    "        recon_x = self.decoder(latent)\n",
    "        return recon_x, mean, logvar, latent\n",
    "       \n",
    "    \n",
    "#### LOSS FUNCTIONS\n",
    "# gives option for VAE type of loss\n",
    "def old_mse_loss(x, recon_x, weights=None):\n",
    "    return F.mse_loss(\n",
    "        recon_x, x, \n",
    "    ) * 1e5\n",
    "\n",
    "\n",
    "def discrim_criter(pred, true):\n",
    "    return F.binary_cross_entropy_with_logits(\n",
    "        pred, true,\n",
    "    ) * 1e5\n",
    "\n",
    "\n",
    "def weighted_mse(a, b, weights=None):\n",
    "    return (\n",
    "        torch.sum(((a-b)**2)*weights) if (weights is not None)\n",
    "        else F.mse_loss(a, b)\n",
    "    ) * 1e5\n",
    "\n",
    "def old_vae_loss(x, recon_x, mean, logvar, weights=None, this_lambda=0.,):\n",
    "    if weights is None:\n",
    "        bce = F.mse_loss(\n",
    "            recon_x, x, \n",
    "        ) * 1e5  # poss comment out last part \n",
    "    else:\n",
    "        bce = weighted_mse(recon_x, x, weights=weights)\n",
    "   \n",
    "    kl_div = -.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    \n",
    "    return bce + this_lambda*kl_div\n",
    "\n",
    "def discrim_loss(pred, true):\n",
    "    return F.binary_cross_entropy_with_logits(\n",
    "        pred, true, \n",
    "    ) * 1e5\n",
    "\n",
    "# don't do any requires_grad stuff in here\n",
    "def adv_vae_loss(\n",
    "    x, recon_x, \n",
    "    mean, logvar, discrim_preds,\n",
    "    alpha, beta, weights=None,\n",
    "):\n",
    "    vae_part_loss = old_vae_loss(\n",
    "        x, recon_x, mean, logvar, weights=weights)\n",
    "    source_label = [1., 0.]\n",
    "    target_label = [0., 1.]\n",
    "    discrim_labels = torch.tensor([source_label] * x.shape[0]).to(device)\n",
    "    total_discrim_loss = F.binary_cross_entropy_with_logits(\n",
    "        discrim_preds, discrim_labels, \n",
    "    ) * 1e5\n",
    "    \n",
    "    discrim_part_loss = beta * total_discrim_loss\n",
    "    return alpha * vae_part_loss + discrim_part_loss, vae_part_loss, total_discrim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include everything or only the non clonotypes\n",
    "# do everything (how gte the clonotypes)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "train_feature = omics_train.X.todense() / .1  # don't have this\n",
    "\n",
    "# very small number on this one \n",
    "batch_size = 1<<7\n",
    "epochs = 30  \n",
    "\n",
    "ref_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(train_feature),\n",
    "    ), batch_size=batch_size,\n",
    "    shuffle=True, num_workers=1, pin_memory=True,\n",
    ")\n",
    "\n",
    "input_cell_dim = 19089\n",
    "\n",
    "\n",
    "# ODD FINDING - DEEPER MAKES LATENT SPACE LOOK BETTER\n",
    "# ALSO LARGER HIDDEN DIM BY FACTOR OF 2\n",
    "ref_vae = VAE(\n",
    "    StandardEncoder(input_cell_dim, 1<<7, hidden_dim=1<<11),  # hidden was 1<<10\n",
    "    StandardDecoder(input_cell_dim, 1<<7, hidden_dim=1<<11,),\n",
    "    is_vae=False,\n",
    "    use_latent_norm=True,  # was True for all else \n",
    ").to(device)\n",
    "\n",
    "ref_vae_opt = optim.Adam( #5-5 is 181\n",
    "    ref_vae.parameters(), lr=1e-5, #betas=(.5,.999), 5e get .074, after 10, same is avg .057\n",
    ")\n",
    "\n",
    "ref_vae.to(device)\n",
    "\n",
    "epoch_losses = []\n",
    "    \n",
    "need_retrain = 0    \n",
    "if need_retrain:    \n",
    "    epochs = 30\n",
    "    # got to < .115 avg loss after 150 epochs\n",
    "    # best was ====> Epoch: 1000 Average loss: 0.0979890559\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_loss = 0.0\n",
    "        for _id, [batch,] in enumerate(ref_data_loader):\n",
    "            batch = batch.to(device)\n",
    "            ref_vae_opt.zero_grad()\n",
    "\n",
    "            recon_x, mean, logvar, latent = ref_vae(batch)\n",
    "            batch_loss = old_vae_loss(\n",
    "                batch, recon_x, mean, logvar, weights=None,\n",
    "            )\n",
    "\n",
    "\n",
    "            batch_loss.backward()\n",
    "            epoch_loss += batch_loss.item()\n",
    "            ref_vae_opt.step()\n",
    "            if not (_id % 500):\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.10f}'.format(\n",
    "                    epoch, \n",
    "                    _id * len(batch), \n",
    "                    len(ref_data_loader.dataset),\n",
    "                    25. * _id / len(ref_data_loader),\n",
    "                    batch_loss.item() / len(batch),\n",
    "                ))\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.10f}'.format(\n",
    "                  epoch, epoch_loss / len(ref_data_loader.dataset)))\n",
    "\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "else:\n",
    "    ref_vae.load_state_dict(torch.load('ref_vae.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1<<7\n",
    "ref_vae = ref_vae.to('cpu')\n",
    "\n",
    "orig_cells_dataset = (\n",
    "    torch\n",
    "    .from_numpy(train_feature)\n",
    "    .float()\n",
    "    .to('cpu')\n",
    ")\n",
    "\n",
    "_, _, _, latent = ref_vae(orig_cells_dataset)\n",
    "\n",
    "latent = latent.detach().numpy()\n",
    "\n",
    "annos = np.unique(omics_data.obs['leiden_cell_type'])\n",
    "anno_to_label = dict(zip(annos, range(len(annos))))\n",
    "label_to_anno = dict(zip(range(len(annos)), annos))\n",
    "final_output_shape = len(label_to_anno)\n",
    "\n",
    "celltype_classifier = Discriminator(latent_dim, end_dim=final_output_shape).to(device)\n",
    "\n",
    "celltype_classifier_opt = optim.Adam(\n",
    "    celltype_classifier.parameters(), lr=1e-3,\n",
    ")\n",
    "\n",
    "batch_size = 1<<5\n",
    "\n",
    "\n",
    "celltype_train_list = np.array([\n",
    "    anno_to_label[ct] \n",
    "    for ct in omics_train.obs['leiden_cell_type']\n",
    "])\n",
    "\n",
    "celltype_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(latent),\n",
    "        torch.from_numpy(celltype_train_list),\n",
    "    ), batch_size=batch_size,\n",
    "    shuffle=True, num_workers=1, pin_memory=True,\n",
    ")\n",
    "\n",
    "num_cells = len(celltype_train_list)\n",
    "class_weights = torch.tensor([\n",
    "    (float(num_cells) / np.sum(celltype_train_list == class_label)) for class_label in range(final_output_shape)\n",
    "]).float()\n",
    "\n",
    "class_weights = class_weights.to(device)\n",
    "criter = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "epochs = 32\n",
    "celltype_classifier = celltype_classifier.to(device)\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for _id, ([this_batch, this_label]) in enumerate(celltype_data_loader):\n",
    "        this_batch = this_batch.to(device)\n",
    "        this_label = this_label.to(device)\n",
    "        celltype_classifier_opt.zero_grad()\n",
    "        predicted_labels = celltype_classifier(this_batch.float())\n",
    "        this_batch_loss = criter(\n",
    "            predicted_labels,\n",
    "            this_label,\n",
    "        )\n",
    "        this_batch_loss.backward()\n",
    "        epoch_loss += this_batch_loss.item()\n",
    "        celltype_classifier_opt.step()\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.10f}'.format(\n",
    "          epoch+1, epoch_loss / len(celltype_data_loader.dataset)))\n",
    "\n",
    "celltype_classifier = celltype_classifier.to('cpu')        \n",
    "orig_pred_labels = celltype_classifier(torch.from_numpy(latent)).detach().numpy()\n",
    "orig_pred_labels = np.argmax(orig_pred_labels, axis=1)\n",
    "num_final_correct = np.sum(orig_pred_labels == celltype_train_list)\n",
    "\n",
    "print(f'final_accuracy:{ num_final_correct / float(num_cells)}')\n",
    "# get around 96 % accuracy, which is solid i suppose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the adversarial wring of the model \n",
    "# first, do cross modal\n",
    "\n",
    "latent_dim = 1<<7\n",
    "sample1_beta = 4e-3 if 0 else 0 # for now, just have this as 0\n",
    "\n",
    "\n",
    "input_cell_dim = 930\n",
    "\n",
    "ref_vae = ref_vae.to(device)\n",
    "raman_vae = VAE(\n",
    "    StandardEncoder(input_cell_dim, 1<<7, hidden_dim=1<<11,),  # hidden was 1<<10\n",
    "    StandardDecoder(input_cell_dim, 1<<7, hidden_dim=1<<11, no_final_relu=True,),\n",
    "    is_vae=False,\n",
    "    use_latent_norm=True,  # was True for all else \n",
    ").to(device)\n",
    "\n",
    "raman_opt = optim.Adam(\n",
    "    raman_vae.parameters(), lr=5e-5, #betas=(.5,.999), 5e get .074, after 10, same is avg .057\n",
    ")\n",
    "\n",
    "raman_vae.to(device)\n",
    "\n",
    "raman_discrim = Discriminator(latent_dim).to(device)\n",
    "\n",
    "raman_discrim_opt = optim.Adam(\n",
    "    raman_discrim.parameters(), lr=4e-3,#5e-4,  # was 1e-5 before, 5e-6, best 1e-4\n",
    ")\n",
    "\n",
    "\n",
    "# now actually do the training  \n",
    "\n",
    "alpha = 1e0  # maybe make this 0 \n",
    "\n",
    "# 8e-4 was good before add in other sample\n",
    "beta = 3e-4 if 1 else 8e-4 if 1 else 2e-3 if 1 else 0 #3e-4  #1e-2   # 1e-8, was best\n",
    "\n",
    "\n",
    "# a good loss for the celltype is .006 ish\n",
    "# 5 was good from when there was extra day 12 in the training \n",
    "raman_beta = 5e1 if 1 else 1e2 # make this big, see if helps\n",
    "\n",
    "\n",
    "print(f\"begin_raman_latent_train\")\n",
    "\n",
    "# variables of interest are:\n",
    "    # raman_device\n",
    "    # raman_vae\n",
    "    # raman_opt\n",
    "    # raman_discrim\n",
    "    # raman_discrim_opt\n",
    "    # raman_discrim_sched\n",
    "\n",
    "# try this and just repeating the ref_key one many times \n",
    "# also make this multip gpus training this is taking a while \n",
    "\n",
    "# train_feature = omics_train.X / .1\n",
    "train_feature = omics_train.X.todense() / .1\n",
    "train_feature_raman = raman_train.X / .1  # see if this helps \n",
    "    \n",
    "ref_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(train_feature),\n",
    "    ), batch_size=batch_size,\n",
    "    shuffle=True, num_workers=1, pin_memory=True,\n",
    ")\n",
    "\n",
    "raman_celltype_train_list = np.array([\n",
    "    anno_to_label[ct] \n",
    "    for ct in raman_train.obs['tg_celltype']\n",
    "])\n",
    "\n",
    "raman_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(train_feature_raman),\n",
    "        torch.from_numpy(raman_celltype_train_list),\n",
    "    ), batch_size=batch_size,\n",
    "    shuffle=True, num_workers=1, pin_memory=True,\n",
    ")\n",
    "\n",
    "celltype_classifier = celltype_classifier.to(device)\n",
    "need_retrain_raman = 0\n",
    "if need_retrain_raman:\n",
    "    # maybe do just ten epochs\n",
    "    epochs = 105 if 1 else 150 if 1 else 90 if 1 else 75 if 0 else 100 if 0 else 30 # (was 150 before)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        discrim_epoch_loss = 0.\n",
    "        vae_part_epoch_loss = 0.\n",
    "        raman_vae_epoch_loss = 0.\n",
    "        celltype_part_epoch_loss = 0.\n",
    "        print(f\"begin epoch {epoch}\")\n",
    "        for _id, ([ref_batch,], [raman_batch, raman_celltypes], ) in enumerate(zip(\n",
    "            ref_data_loader,\n",
    "            raman_data_loader,\n",
    "        )):\n",
    "\n",
    "            raman_opt.zero_grad()\n",
    "            raman_discrim_opt.zero_grad()\n",
    "            ref_batch = ref_batch.to(device)\n",
    "            raman_batch = raman_batch.to(device)\n",
    "            raman_celltypes = raman_celltypes.to(device)\n",
    "\n",
    "            ref_encoded = (\n",
    "                ref_vae.get_latent(ref_batch)\n",
    "                .detach()\n",
    "            )\n",
    "\n",
    "            raman_encoded = (\n",
    "                raman_vae.get_latent(raman_batch)\n",
    "                .detach()\n",
    "            )\n",
    "\n",
    "            # put all tensors on the right device \n",
    "            source_label, target_label = [1., 0.], [0., 1.]\n",
    "            encodeds = torch.cat((ref_encoded, raman_encoded), axis=0)\n",
    "            discrim_labels = torch.tensor(\n",
    "                [source_label] * ref_encoded.shape[0]\n",
    "                + [target_label] * raman_encoded.shape[0]\n",
    "            ).to(device)\n",
    "\n",
    "            pred_discrim_labels = raman_discrim(encodeds)\n",
    "            batch_discrim_loss = discrim_loss(\n",
    "                pred_discrim_labels, discrim_labels,\n",
    "            )\n",
    "\n",
    "            batch_discrim_loss.backward()\n",
    "            discrim_epoch_loss += batch_discrim_loss.item()\n",
    "            raman_discrim_opt.step()     \n",
    "\n",
    "\n",
    "            #### second part\n",
    "            for param in raman_discrim.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            recon_raman_batch, raman_batch_mean, raman_batch_logvar, raman_batch_latent = raman_vae(raman_batch)\n",
    "\n",
    "            # this was from before, do not use this\n",
    "    #                 raman_batch_latent = raman_vae.reparam_trick(raman_batch_mean, raman_batch_logvar)\n",
    "            raman_vae_discrim_preds = raman_discrim(raman_batch_latent)\n",
    "\n",
    "            # set the discrim requires_grad to False \n",
    "\n",
    "            raman_vae_batch_loss, vae_part_batch_loss, _ = adv_vae_loss(\n",
    "                raman_batch.detach(), recon_raman_batch, # second_batch_latent,\n",
    "                raman_batch_mean, raman_batch_logvar, raman_vae_discrim_preds,\n",
    "                alpha, beta,   # was 1e-1, 1e-2 was bad, 1e-1 was best \n",
    "            )\n",
    "\n",
    "            #### next part THIS IS NEW \n",
    "            raman_celltype_preds = celltype_classifier(raman_batch_latent)\n",
    "            raman_celltype_loss =  criter(raman_celltype_preds, raman_celltypes)\n",
    "            raman_vae_batch_loss = raman_vae_batch_loss + raman_beta * raman_celltype_loss\n",
    "\n",
    "            raman_vae_batch_loss.backward()\n",
    "            celltype_part_epoch_loss += raman_celltype_loss.item()\n",
    "            raman_vae_epoch_loss += raman_vae_batch_loss.item()\n",
    "            vae_part_epoch_loss += vae_part_batch_loss.item()\n",
    "            raman_opt.step()\n",
    "\n",
    "            # undo the above\n",
    "            for param in raman_discrim.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "\n",
    "            if not (_id % 500):\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses: {:.6f} {:.6f}'.format(\n",
    "                epoch, _id * len(raman_batch), len(raman_data_loader.dataset),\n",
    "                100. * _id / len(raman_data_loader),\n",
    "                batch_discrim_loss.item() / len(raman_batch),\n",
    "                raman_vae_batch_loss.item() / len(raman_batch)))\n",
    "\n",
    "        print('====> Epoch: {} Average adv vae loss: {:.10f}'.format(\n",
    "              epoch, raman_vae_epoch_loss / len(raman_data_loader.dataset)))\n",
    "\n",
    "        print('====> Epoch: {} Average vae part loss: {:.10f}'.format(\n",
    "              epoch, vae_part_epoch_loss / len(raman_data_loader.dataset)))\n",
    "\n",
    "        print('====> Epoch: {} Average celltype part loss: {:.10f}'.format(\n",
    "              epoch, celltype_part_epoch_loss / len(raman_data_loader.dataset)))\n",
    "\n",
    "        print('====> Epoch: {} Average discrim vae loss: {:.10f}'.format(\n",
    "              epoch, discrim_epoch_loss / len(raman_data_loader.dataset)))\n",
    "\n",
    "        print(f\"end epoch {epoch}\")\n",
    "        if 0 and vae_part_epoch_loss >  .9 * raman_vae_epoch_loss:\n",
    "            beta *= 2\n",
    "            print(f\"updating at epoch {epoch} to beta {beta}\")\n",
    "    print(f\"end_raman_latent_train\")\n",
    "\n",
    "else:\n",
    "    raman_vae.load_state_dict(torch.load('raman_vae.pt'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how well transferred and originals align\n",
    "transfer_vae = VAE(\n",
    "    raman_vae.encoder,\n",
    "    ref_vae.decoder,\n",
    "    is_vae=False,\n",
    "    use_latent_norm=True,  # was True for all else \n",
    ")\n",
    "\n",
    "transfer_vae = transfer_vae.to('cpu')\n",
    "ref_vae = ref_vae.to('cpu')\n",
    "\n",
    "\n",
    "orig_cells_dataset = (\n",
    "    torch\n",
    "    .from_numpy(train_feature)\n",
    "    .float()\n",
    "    .to('cpu')\n",
    ")\n",
    "\n",
    "\n",
    "recon, _, _, _ = ref_vae(orig_cells_dataset)\n",
    "\n",
    "\n",
    "orig_cells_dataset_raman = (\n",
    "    torch\n",
    "    .from_numpy(train_feature_raman)\n",
    "    .float()\n",
    "    .to('cpu')\n",
    ")\n",
    "\n",
    "recon_raman, _, _, _ = transfer_vae(orig_cells_dataset_raman)\n",
    "\n",
    "\n",
    "recon_adata = sc.AnnData(recon.detach().numpy())\n",
    "recon_adata.obs = omics_train.obs\n",
    "recon_adata_raman = sc.AnnData(recon_raman.detach().numpy())\n",
    "recon_adata_raman.obs = raman_train.obs\n",
    "together_recon = recon_adata.concatenate(recon_adata_raman)\n",
    "\n",
    "sc.pp.pca(together_recon, n_comps=30)\n",
    "sc.pp.neighbors(together_recon, n_neighbors=30)\n",
    "sc.tl.umap(together_recon)\n",
    "\n",
    "sc.pl.umap(together_recon, color='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(together_recon, color=['batch', 'leiden_cell_type', 'tg_celltype', 'together_celltype'], wspace=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
