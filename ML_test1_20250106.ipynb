{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_list = [3,5]\n",
    "results = np.zeros((len(test_list),10000))\n",
    "for i,seq in enumerate(test_list):\n",
    "    results[i,seq] = 1\n",
    "print(results[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(2,2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9716, 0.7362],\n",
       "        [0.4634, 0.5269]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2)\n",
    "print(x.dtype)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2,dtype=torch.int)\n",
    "print(x.dtype)\n",
    "print(x.size())\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.1000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.5,0.1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4423, 0.8018],\n",
      "        [0.4140, 0.6367]])\n",
      "tensor([[0.1202, 0.7941],\n",
      "        [0.3590, 0.2611]])\n",
      "tensor([[0.5625, 1.5959],\n",
      "        [0.7731, 0.8978]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z = x + y\n",
    "# z = torch.add(x,y) # same thing\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5625, 1.5959],\n",
      "        [0.7731, 0.8978]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2860, 0.6924, 0.8349],\n",
      "        [0.0022, 0.5082, 0.4735],\n",
      "        [0.6729, 0.2206, 0.5432],\n",
      "        [0.4328, 0.4804, 0.6429],\n",
      "        [0.6591, 0.4975, 0.2792]])\n",
      "tensor(0.5082)\n",
      "0.5081883668899536\n"
     ]
    }
   ],
   "source": [
    "# basic operations\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[1,1])\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2372, 0.5054, 0.5252, 0.7590],\n",
      "        [0.8056, 0.5363, 0.7044, 0.8650],\n",
      "        [0.6220, 0.4578, 0.1259, 0.5947],\n",
      "        [0.8848, 0.0391, 0.6409, 0.6885]])\n",
      "tensor([0.2372, 0.5054, 0.5252, 0.7590, 0.8056, 0.5363, 0.7044, 0.8650, 0.6220,\n",
      "        0.4578, 0.1259, 0.5947, 0.8848, 0.0391, 0.6409, 0.6885])\n",
      "tensor([[0.2372, 0.5054, 0.5252, 0.7590, 0.8056, 0.5363, 0.7044, 0.8650],\n",
      "        [0.6220, 0.4578, 0.1259, 0.5947, 0.8848, 0.0391, 0.6409, 0.6885]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "z = x.view(2,8) # -1,8 also works\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# if we use cpu, a and b will share the same memory location, \n",
    "# but when using gpu, they are in different locations. \n",
    "print(a + 1) \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # calculate the gradients\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N 2x (w*x -y)\n",
    "\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x,y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "\n",
    "    # gradients\n",
    "    dw = gradient(X,Y,y_pred)\n",
    "\n",
    "    #update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "\n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    with torch.no_grad():\n",
    "        #update weights\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = 2.701\n",
      "epoch 1: w = 2.530, loss = 14.60078430\n",
      "epoch 11: w = 1.791, loss = 0.08225676\n",
      "epoch 21: w = 1.834, loss = 0.04216808\n",
      "epoch 31: w = 1.878, loss = 0.02295874\n",
      "epoch 41: w = 1.910, loss = 0.01250054\n",
      "epoch 51: w = 1.933, loss = 0.00680627\n",
      "epoch 61: w = 1.951, loss = 0.00370587\n",
      "epoch 71: w = 1.964, loss = 0.00201776\n",
      "epoch 81: w = 1.973, loss = 0.00109863\n",
      "epoch 91: w = 1.980, loss = 0.00059817\n",
      "Prediction after training: f(5) = 9.969\n"
     ]
    }
   ],
   "source": [
    "# 1) Design model (input, output size, forward pass)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "# - forward pass: compute prediction\n",
    "# - backward pass: gradients\n",
    "# - update our weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test = torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "# model prediction\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearModel,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dim,output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = nn.Linear(input_size, output_size) \n",
    "\n",
    "model = LinearModel(input_size, output_size) # same thing\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# loss = MSE\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "\n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "     \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4]).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model input, output size, forward pas\n",
    "# 2) Construct loss optimizer\n",
    "# 3) Training loop\n",
    "#     - forward pass: compute prediction and loss\n",
    "#     - backward pass: gradients\n",
    "#     - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 4429.8740\n",
      "epoch: 20, loss = 3305.2041\n",
      "epoch: 30, loss = 2491.1091\n",
      "epoch: 40, loss = 1901.2137\n",
      "epoch: 50, loss = 1473.3636\n",
      "epoch: 60, loss = 1162.7690\n",
      "epoch: 70, loss = 937.1111\n",
      "epoch: 80, loss = 773.0391\n",
      "epoch: 90, loss = 653.6625\n",
      "epoch: 100, loss = 566.7505\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size,output_size)\n",
    "\n",
    "# loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted,y)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted,'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch: 10, loss = 0.6471\n",
      "epoch: 20, loss = 0.5222\n",
      "epoch: 30, loss = 0.4449\n",
      "epoch: 40, loss = 0.3924\n",
      "epoch: 50, loss = 0.3542\n",
      "epoch: 60, loss = 0.3248\n",
      "epoch: 70, loss = 0.3014\n",
      "epoch: 80, loss = 0.2823\n",
      "epoch: 90, loss = 0.2662\n",
      "epoch: 100, loss = 0.2525\n",
      "accuracy = 0.9211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-4.png)\n",
    "![alt text](./images/image-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./data/wine.csv',delimiter=\",\", dtype=np.float32,skiprows=1)\n",
    "        # self.x = torch.from_numpy(xy[:,1:])\n",
    "        # self.y = torch.from_numpy(xy[:,[0]]) # [0] will lead to a nsamples x 1 array\n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:, [0]]\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(dataset) \n",
    "        return self.n_samples\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self,sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n",
      "Dataset size: 178\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features,labels = first_data\n",
    "print(features, labels)\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tensor([1,2,3,4],dtype=torch.float32).view(-1,1)\n",
    "torch.tensor([1,2,3,4],dtype=torch.float32).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "# num_workers=0：数据加载在主进程中顺序执行（单线程）。这是默认设置。\n",
    "# num_workers>0：数据加载会使用多线程并行加载，num_workers 表示线程数量。\n",
    "\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / 4)\n",
    "print(total_samples,n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "# fashion-mnist,, cifar, coco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-6.png)\n",
    "![alt text](./images/image-7.png)\n",
    "![alt text](./images/image-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch: tensor([0.6590, 0.2424, 0.0986], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "outputs = torch.softmax(x,dim=0)\n",
    "print('softmax torch:', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![alt text](./images/image-10.png)\n",
    " ![alt text](./images/image-11.png)\n",
    " ![alt text](./images/image-12.png)\n",
    " ![alt text](./images/image-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-14.png)\n",
    "![alt text](./images/image-15.png)\n",
    "![alt text](./images/image-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n",
      "Loss1 numpy: 0.7679\n",
      "Loss2 numpy: 1.3533\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "Y_pred_good = np.array([0.7,0.2,0.1])\n",
    "Y_pred_bad = np.array([0.1,0.3,0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n",
    "\n",
    "Y_pred_good_sm = softmax(Y_pred_good)\n",
    "Y_pred_bad_sm = softmax(Y_pred_bad)\n",
    "l1 = cross_entropy(Y, Y_pred_good_sm)\n",
    "l2 = cross_entropy(Y, Y_pred_bad_sm)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7679495811462402\n",
      "1.3532865047454834\n",
      "tensor([0])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "# nsamples x nclasses = 1 x 3\n",
    "Y_pred_good = torch.tensor([[0.7,0.2,0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.1,0.3,0.6]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad,Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-19.png)\n",
    "![alt text](./images/image-20.png)\n",
    "![alt text](./images/image-22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forwad(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # nn.Sigmoid\n",
    "        # nn.Softmax\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size)\n",
    "    \n",
    "    def forwad(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # F.leaky_relu()\n",
    "        # F.tanh()\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet2(input_size=28*28,hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss() #(applies Softmax)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet1(input_size=28*28,hidden_size=5)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/image-23.png)\n",
    "![alt text](./images/image-24.png)\n",
    "![alt text](./images/image-25.png)\n",
    "![alt text](./images/image-26.png)\n",
    "![alt text](./images/image-27.png)\n",
    "![alt text](./images/image-28.png)\n",
    "![alt text](./images/image-29.png)\n",
    "![alt text](./images/image-30.png)\n",
    "![alt text](./images/image-31.png)\n",
    "![alt text](./images/image-32.png)\n",
    "![alt text](./images/image-33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.SiLU()`（也称为**Swish**）是一种激活函数，它是一个平滑的非线性激活函数，定义为：\n",
    "\n",
    "\\[\n",
    "\\text{Swish}(x) = x \\cdot \\sigma(x)\n",
    "\\]\n",
    "\n",
    "其中，\\(\\sigma(x)\\) 是Sigmoid函数，即：\n",
    "\n",
    "\\[\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\]\n",
    "\n",
    "所以，Swish函数是输入 \\(x\\) 和Sigmoid函数的输出 \\(\\sigma(x)\\) 的乘积。Swish的一个特点是它是一个**连续的可微函数**，并且没有像ReLU那样存在死区问题（即当输入为负时输出恒为零）。\n",
    "\n",
    "### Swish与ReLU的区别：\n",
    "\n",
    "1. **数学表达式**：\n",
    "   - **ReLU**：\\( \\text{ReLU}(x) = \\max(0, x) \\)\n",
    "   - **Swish**：\\( \\text{Swish}(x) = x \\cdot \\sigma(x) \\)\n",
    "\n",
    "2. **性质**：\n",
    "   - **ReLU** 在 \\(x < 0\\) 时输出为零，在 \\(x > 0\\) 时输出为 \\(x\\)。这可能导致神经元“死亡”问题——即输入为负时，ReLU的输出始终为零，可能导致梯度为零，进而无法学习。\n",
    "   - **Swish** 在整个输入范围内都具有平滑的梯度，不会出现ReLU那种死区问题。其输出在负输入时也是非零的，因为即使 \\(x\\) 为负，\\(\\sigma(x)\\) 的值仍然是一个正数，从而使得 Swish 不会完全为零。\n",
    "\n",
    "3. **性能**：\n",
    "   - 在某些任务中，Swish 激活函数已经被证明能够提供比 ReLU 更好的性能，尤其是在深度神经网络中。它的平滑性帮助了模型在训练中收敛得更好。\n",
    "   - 然而，Swish 比 ReLU 计算更复杂，因为它需要计算Sigmoid函数，而 ReLU只需要一个比较操作。\n",
    "\n",
    "### 总结：\n",
    "\n",
    "- **ReLU** 是简单且高效的激活函数，广泛应用于各种神经网络架构，但它可能会导致“神经元死亡”问题。\n",
    "- **Swish** 是一个更平滑的激活函数，通常在更深的网络或特定任务中表现更好，因为它避免了ReLU的死区问题。\n",
    "\n",
    "你可以通过实验选择适合你任务的激活函数，通常情况下，ReLU适用于大多数场景，而Swish可以在一些更复杂的网络中提供更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我无法直接画图，但我可以给你描述它们的轨迹，并解释它们之间的区别，以及什么时候使用 `SiLU`（Swish）激活函数。\n",
    "\n",
    "### **SiLU（Swish）的轨迹**：\n",
    "- **SiLU (Swish)** 的函数形式是：\\( \\text{SiLU}(x) = x \\cdot \\sigma(x) = \\frac{x}{1 + e^{-x}} \\)\n",
    "- 当输入 \\(x\\) 为负时，`SiLU(x)` 仍然是负的，但不为零，而是一个小的负值。\n",
    "- 当输入 \\(x\\) 为零时，`SiLU(0)` 的输出为零。\n",
    "- 当输入 \\(x\\) 为正时，`SiLU(x)` 的输出会跟随 \\(x\\) 的增大而增大，但会比 ReLU 更加平滑，并不会像 ReLU 那样“陡峭”地跳跃。\n",
    "\n",
    "**形状描述**：  \n",
    "- **负区间**：随着 \\(x\\) 变负，`SiLU(x)` 逐渐增大但永远不会为零。相对于ReLU，`SiLU(x)` 在负数时也有较为平滑的变化。\n",
    "- **正区间**：在 \\(x\\) 为正时，`SiLU(x)` 的输出接近于 \\(x\\)，但与 ReLU 不同，`SiLU(x)` 在正值时不会立即变为线性，它的增速逐渐加快，表现出更平滑的过渡。\n",
    "\n",
    "### **Leaky ReLU vs SiLU**\n",
    "\n",
    "**Leaky ReLU** 的函数形式是：\n",
    "\n",
    "\\[\n",
    "\\text{LeakyReLU}(x) = \\begin{cases}\n",
    "x, & x \\geq 0 \\\\\n",
    "\\alpha x, & x < 0\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "其中，\\(\\alpha\\) 是一个非常小的常数（比如 0.01）。在 \\(x < 0\\) 时，Leaky ReLU 不会像 ReLU 那样输出零，而是输出一个较小的负值。\n",
    "\n",
    "### **Leaky ReLU 和 SiLU 的区别**：\n",
    "\n",
    "1. **负区间的处理**：\n",
    "   - **Leaky ReLU**：当输入 \\(x\\) 为负时，输出为 \\( \\alpha \\cdot x \\)，是一个较小的负数，通常是线性的。\n",
    "   - **SiLU (Swish)**：当输入为负时，输出仍然是负值，但不是简单的线性负数，而是通过Sigmoid函数调整过的，因此输出不会像Leaky ReLU那样是线性的负数，具有更平滑的过渡。\n",
    "\n",
    "2. **正区间的处理**：\n",
    "   - **Leaky ReLU**：当输入为正时，输出直接等于 \\(x\\)，是线性的。\n",
    "   - **SiLU (Swish)**：当输入为正时，输出也是正值，但由于包含了 Sigmoid 函数，输出变化更加平滑，增速比Leaky ReLU慢。\n",
    "\n",
    "3. **平滑性**：\n",
    "   - **Leaky ReLU** 由于其线性特性，梯度在负值区间是恒定的，可能会在某些情况下导致不稳定的学习。\n",
    "   - **SiLU (Swish)** 是一个平滑的非线性函数，能够避免Leaky ReLU那种突然的变化，可能在深度神经网络中表现得更好。\n",
    "\n",
    "### **什么时候使用 SiLU (Swish)**？\n",
    "\n",
    "1. **深度神经网络（DNN）和较深的网络**：  \n",
    "   在一些深度网络（特别是深度学习中一些更复杂的模型）中，Swish函数通常能比ReLU和Leaky ReLU表现得更好，特别是在避免梯度消失和神经元死亡问题上。\n",
    "   \n",
    "2. **当你希望平滑的梯度**：  \n",
    "   SiLU 在训练过程中提供更平滑的梯度，这对于一些需要精细梯度调整的任务（例如生成对抗网络、强化学习等）会很有帮助。\n",
    "\n",
    "3. **大规模任务和复杂任务**：  \n",
    "   如果你正在处理一个有多个层次的神经网络任务，Swish 可能会比传统的 ReLU 或 Leaky ReLU 更有优势，特别是当模型变得非常深时，Swish 的平滑性能有效提升训练的稳定性和收敛速度。\n",
    "\n",
    "4. **非线性增强**：  \n",
    "   对于某些任务，SiLU的非线性效果能够帮助网络更好地建模复杂的关系，尤其是在任务涉及到大量非线性特征时，Swish可能提供更好的表示能力。\n",
    "\n",
    "### **总结**：\n",
    "- **SiLU (Swish)** 是一个平滑且非线性的激活函数，能够避免 ReLU 中的“神经元死亡”问题。\n",
    "- **Leaky ReLU** 是一个在负数区间有小斜率的激活函数，避免了标准 ReLU 的死区问题，但相比于 Swish，Leaky ReLU 缺乏那么平滑的特性。\n",
    "- 使用 `SiLU`（Swish）主要是为了获得更平滑、更稳定的训练，尤其适用于深度学习模型、复杂任务以及大规模神经网络。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
