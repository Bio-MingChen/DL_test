{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data.shape)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0105, 0.7984],\n",
      "        [0.9866, 0.3261]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data,dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0799, 0.9788, 0.0095],\n",
      "        [0.6659, 0.6016, 0.3410]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f'Shape of tensor: {tensor.shape}')\n",
    "print(f'Datatype of tensor: {tensor.dtype}')\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "\n",
    "tensor = torch.ones(4,4)\n",
    "print(f'First row: {tensor[0]}')\n",
    "print(f'First column: {tensor[:,0]}')\n",
    "print(f'Last column: {tensor[...,-1]}')\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor,tensor.T,out=y3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵乘法并不意味着简单地将一个矩阵映射到另一个矩阵的形状上。矩阵乘法实际上是基于线性代数的定义，涉及到行和列之间的点乘计算。让我们详细讲解矩阵乘法的过程，特别是在本例中的计算方式。\n",
    "\n",
    "### 矩阵乘法的基本规则\n",
    "\n",
    "在矩阵乘法 \\( A @ B \\) 中，假设：\n",
    "- \\( A \\) 是一个形状为 \\( (m, n) \\) 的矩阵\n",
    "- \\( B \\) 是一个形状为 \\( (n, p) \\) 的矩阵\n",
    "\n",
    "那么，矩阵乘法 \\( A @ B \\) 的结果将是一个形状为 \\( (m, p) \\) 的矩阵。\n",
    "\n",
    "乘法的计算方式是：  \n",
    "**第 \\( i \\) 行和第 \\( j \\) 列的元素**是通过将 \\( A \\) 的第 \\( i \\) 行与 \\( B \\) 的第 \\( j \\) 列进行“点积”得到的。\n",
    "\n",
    "具体来说：\n",
    "\n",
    "\\[\n",
    "C[i, j] = \\sum_{k=1}^{n} A[i, k] \\times B[k, j]\n",
    "\\]\n",
    "\n",
    "其中，\\( A[i, k] \\) 是矩阵 \\( A \\) 中第 \\( i \\) 行，第 \\( k \\) 列的元素，\\( B[k, j] \\) 是矩阵 \\( B \\) 中第 \\( k \\) 行，第 \\( j \\) 列的元素，\\( C[i, j] \\) 是矩阵乘积 \\( C = A @ B \\) 中第 \\( i \\) 行，第 \\( j \\) 列的元素。\n",
    "\n",
    "### 本例中的矩阵乘法\n",
    "\n",
    "现在回到本例的代码：\n",
    "\n",
    "```python\n",
    "tensor = torch.tensor([[1., 0., 1., 1.],\n",
    "                       [1., 0., 1., 1.],\n",
    "                       [1., 0., 1., 1.],\n",
    "                       [1., 0., 1., 1.]])\n",
    "y1 = tensor @ tensor.T\n",
    "```\n",
    "\n",
    "在这个例子中，`tensor` 是一个 \\( 4 \\times 4 \\) 的矩阵，内容如下：\n",
    "\n",
    "\\[\n",
    "\\text{tensor} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 1 & 1 \\\\\n",
    "1 & 0 & 1 & 1 \\\\\n",
    "1 & 0 & 1 & 1 \\\\\n",
    "1 & 0 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "我们进行的是 `tensor` 与其转置 `tensor.T` 的矩阵乘法。\n",
    "\n",
    "`tensor.T` 的转置矩阵是：\n",
    "\n",
    "\\[\n",
    "\\text{tensor.T} = \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "矩阵乘法的计算过程如下：\n",
    "\n",
    "#### 第 1 行第 1 列\n",
    "\n",
    "计算 \\( y1[1,1] \\)：\n",
    "- `tensor` 的第 1 行是 \\( [1, 0, 1, 1] \\)\n",
    "- `tensor.T` 的第 1 列是 \\( [1, 1, 1, 1] \\)\n",
    "\n",
    "点乘的计算为：\n",
    "\n",
    "\\[\n",
    "y1[1, 1] = (1 \\times 1) + (0 \\times 1) + (1 \\times 1) + (1 \\times 1) = 3\n",
    "\\]\n",
    "\n",
    "#### 第 1 行第 2 列\n",
    "\n",
    "计算 \\( y1[1,2] \\)：\n",
    "- `tensor` 的第 1 行是 \\( [1, 0, 1, 1] \\)\n",
    "- `tensor.T` 的第 2 列是 \\( [0, 0, 0, 0] \\)\n",
    "\n",
    "点乘的计算为：\n",
    "\n",
    "\\[\n",
    "y1[1, 2] = (1 \\times 0) + (0 \\times 0) + (1 \\times 0) + (1 \\times 0) = 0\n",
    "\\]\n",
    "\n",
    "但是在这里，`tensor` 的每一行都是一样的，所以和 `tensor.T` 中的列的计算会得到相同的值。由于 `tensor` 的每行都是一样的，最终所有元素的计算结果都一样，都是 3。\n",
    "\n",
    "### 结果是一个对称矩阵\n",
    "\n",
    "由于 `tensor` 的每一行都相同，`tensor.T` 的每一列也相同，因此矩阵乘法的结果将是一个对称矩阵，其每个元素都为 3。矩阵乘法的结果如下：\n",
    "\n",
    "\\[\n",
    "y1 = \n",
    "\\begin{bmatrix}\n",
    "3 & 3 & 3 & 3 \\\\\n",
    "3 & 3 & 3 & 3 \\\\\n",
    "3 & 3 & 3 & 3 \\\\\n",
    "3 & 3 & 3 & 3\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "### 关键点总结：\n",
    "\n",
    "- **矩阵乘法**：是行与列之间的点乘操作。\n",
    "- 在本例中，`tensor` 的行和列都非常相似，导致了矩阵乘法结果的所有元素都相同。\n",
    "- `tensor @ tensor.T` 和 `tensor.matmul(tensor.T)` 的计算结果是一样的，因为它们本质上执行的是同样的矩阵乘法。\n",
    "- 本例的结果是一个 \\( 4 \\times 4 \\) 的矩阵，每个元素都是 3，因为所有的行和列之间的点乘结果都相同。\n",
    "\n",
    "所以，矩阵乘法的核心并不是形状映射，而是通过行列之间的点积计算出结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 \\( X \\) 是一个 \\( 4 \\times 4 \\) 的矩阵，而 \\( Y \\) 是一个 \\( 4 \\times 2 \\) 的矩阵，矩阵乘法 \\( X @ Y \\) 是有效的，并且我们可以进行乘法运算。\n",
    "\n",
    "### 矩阵乘法的条件\n",
    "\n",
    "矩阵乘法的条件是：  \n",
    "**矩阵 \\( A \\) 和矩阵 \\( B \\) 相乘时，矩阵 \\( A \\) 的列数必须等于矩阵 \\( B \\) 的行数。**\n",
    "\n",
    "在本例中：\n",
    "- \\( X \\) 是 \\( 4 \\times 4 \\) 矩阵（4 行 4 列）。\n",
    "- \\( Y \\) 是 \\( 4 \\times 2 \\) 矩阵（4 行 2 列）。\n",
    "\n",
    "所以，矩阵乘法 \\( X @ Y \\) 是有效的，因为 \\( X \\) 的列数（4）等于 \\( Y \\) 的行数（4）。乘积矩阵 \\( Z = X @ Y \\) 的结果将会是一个 \\( 4 \\times 2 \\) 的矩阵。\n",
    "\n",
    "### 矩阵乘法的计算\n",
    "\n",
    "假设：\n",
    "- \\( X \\) 的形状为 \\( 4 \\times 4 \\)\n",
    "- \\( Y \\) 的形状为 \\( 4 \\times 2 \\)\n",
    "\n",
    "结果矩阵 \\( Z \\) 的形状将是 \\( 4 \\times 2 \\)。\n",
    "\n",
    "#### 计算 \\( Z \\) 中的每个元素\n",
    "\n",
    "矩阵乘法的计算方式是行与列之间的点积。对于每个元素 \\( Z[i, j] \\)，我们需要计算 \\( X \\) 的第 \\( i \\) 行和 \\( Y \\) 的第 \\( j \\) 列的点积：\n",
    "\n",
    "\\[\n",
    "Z[i, j] = \\sum_{k=1}^{4} X[i, k] \\times Y[k, j]\n",
    "\\]\n",
    "\n",
    "也就是说，结果矩阵 \\( Z \\) 中的第 \\( i \\) 行第 \\( j \\) 列的元素是 \\( X \\) 的第 \\( i \\) 行与 \\( Y \\) 的第 \\( j \\) 列相对应元素的乘积之和。\n",
    "\n",
    "### 例子\n",
    "\n",
    "假设有以下矩阵 \\( X \\) 和 \\( Y \\)：\n",
    "\n",
    "\\[\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 \\\\\n",
    "5 & 6 & 7 & 8 \\\\\n",
    "9 & 10 & 11 & 12 \\\\\n",
    "13 & 14 & 15 & 16\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "Y = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \\\\\n",
    "7 & 8\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "#### 计算 \\( Z = X @ Y \\)\n",
    "\n",
    "1. **第 1 行第 1 列的元素：**\n",
    "\n",
    "   \\[\n",
    "   Z[1, 1] = (1 \\times 1) + (2 \\times 3) + (3 \\times 5) + (4 \\times 7) = 1 + 6 + 15 + 28 = 50\n",
    "   \\]\n",
    "\n",
    "2. **第 1 行第 2 列的元素：**\n",
    "\n",
    "   \\[\n",
    "   Z[1, 2] = (1 \\times 2) + (2 \\times 4) + (3 \\times 6) + (4 \\times 8) = 2 + 8 + 18 + 32 = 60\n",
    "   \\]\n",
    "\n",
    "3. **第 2 行第 1 列的元素：**\n",
    "\n",
    "   \\[\n",
    "   Z[2, 1] = (5 \\times 1) + (6 \\times 3) + (7 \\times 5) + (8 \\times 7) = 5 + 18 + 35 + 56 = 114\n",
    "   \\]\n",
    "\n",
    "4. **第 2 行第 2 列的元素：**\n",
    "\n",
    "   \\[\n",
    "   Z[2, 2] = (5 \\times 2) + (6 \\times 4) + (7 \\times 6) + (8 \\times 8) = 10 + 24 + 42 + 64 = 140\n",
    "   \\]\n",
    "\n",
    "类似地，计算 \\( Z[3, 1] \\), \\( Z[3, 2] \\), \\( Z[4, 1] \\), 和 \\( Z[4, 2] \\)。\n",
    "\n",
    "最终，矩阵 \\( Z \\) 会是：\n",
    "\n",
    "\\[\n",
    "Z = \n",
    "\\begin{bmatrix}\n",
    "50 & 60 \\\\\n",
    "114 & 140 \\\\\n",
    "178 & 220 \\\\\n",
    "242 & 300\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "### 总结\n",
    "\n",
    "- 矩阵 \\( X \\) 的形状是 \\( 4 \\times 4 \\)，矩阵 \\( Y \\) 的形状是 \\( 4 \\times 2 \\)，它们的乘积 \\( Z = X @ Y \\) 的形状是 \\( 4 \\times 2 \\)。\n",
    "- 计算时，乘积矩阵 \\( Z \\) 的每个元素是 \\( X \\) 的某一行与 \\( Y \\) 的某一列的点积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.) 12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# get numerical value of tensor by item()\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg,agg_item,type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f'{tensor} \\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "n = t.numpy()\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1) # in place operation\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
